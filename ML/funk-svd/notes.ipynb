{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Games - dataset describing the characteristics of each game, including its game type, difficulty, and duration.\n",
    "2. User — dataset containing information regarding user amount of games and amount of reviews \n",
    "3. Recommendation — dataset containing all recommendation data with informations about whether recommendation was funny (number of upvotes), helpful (number of likes), date, is game recommended (yes/no), hours played, user_id and review_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('users.csv')\n",
    "recommendations = pd.read_csv('recommendations.csv')\n",
    "games = pd.read_csv('games.csv')\n",
    "\n",
    "data = recommendations.merge(users, on=\"user_id\").merge(games, on=\"app_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = data['user_id'].unique()\n",
    "app_ids = data['app_id'].unique()\n",
    "user_idx = {id: idx for idx, id in enumerate(user_ids)}\n",
    "app_idx = {id: idx for idx, id in enumerate(app_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "interaction_matrix = np.zeros((len(user_ids), len(app_ids)))\n",
    "for _, row in data.iterrows():\n",
    "    interaction_matrix[user_idx[row['user_id']], app_idx[row['app_id']]] = row['is_recommended']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_file = tempfile.NamedTemporaryFile(delete=False, mode='w+')\n",
    "u_matrix_file = tempfile.NamedTemporaryFile(delete=False, mode='w+')\n",
    "v_matrix_file = tempfile.NamedTemporaryFile(delete=False, mode='w+')\n",
    "\n",
    "# Create and store the interaction matrix\n",
    "for _, row in data.iterrows():\n",
    "    interaction_file.write(f\"{user_idx[row['user_id']]},{app_idx[row['app_id']]},{row['is_recommended']}\\n\")\n",
    "interaction_file.seek(0)  # Reset file pointer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = []\n",
    "interaction_file.seek(0)\n",
    "for line in interaction_file:\n",
    "    interactions.append(line.strip())\n",
    "\n",
    "# Perform train-test split\n",
    "train_interactions, test_interactions = train_test_split(interactions, test_size=0.2, random_state=42)\n",
    "train_file = tempfile.NamedTemporaryFile(delete=False, mode='w+')\n",
    "test_file = tempfile.NamedTemporaryFile(delete=False, mode='w+')\n",
    "for line in train_interactions:\n",
    "    train_file.write(line + \"\\n\")\n",
    "for line in test_interactions:\n",
    "    test_file.write(line + \"\\n\")\n",
    "train_file.seek(0)\n",
    "test_file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "interaction_tempfile_path = interaction_file.name\n",
    "train_tempfile_path = train_file.name\n",
    "test_tempfile_path = test_file.name\n",
    "\n",
    "# Close the temp files\n",
    "interaction_file.close()\n",
    "train_file.close()\n",
    "test_file.close()\n",
    "\n",
    "# Desired permanent file paths\n",
    "interaction_file_path = 'interactions.csv'\n",
    "train_file_path = 'train.csv'\n",
    "test_file_path = 'test.csv'\n",
    "\n",
    "# Rename temp files to permanent files\n",
    "os.rename(interaction_tempfile_path, interaction_file_path)\n",
    "os.rename(train_tempfile_path, train_file_path)\n",
    "os.rename(test_tempfile_path, test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_matrix_tempfile_path = v_matrix_file.name \n",
    "u_matrix_tempfile_path = u_matrix_file.name \n",
    "\n",
    "v_matrix_file.close()\n",
    "u_matrix_file.close()\n",
    "\n",
    "v_matrix_file_path = 'v_matrix.csv'\n",
    "u_matrix_file_path = 'u_matrix.csv'\n",
    "\n",
    "os.rename(v_matrix_tempfile_path, v_matrix_file_path)\n",
    "os.rename(u_matrix_tempfile_path, u_matrix_file_path)\n",
    "v_matrix_file = open('v_matrix.csv', mode='r')\n",
    "u_matrix_file = open('u_matrix.csv', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funk_svd_file(interaction_file, num_users, num_items, num_features=10, learning_rate=0.01, reg_param=0.02, epochs=10):\n",
    "    U = np.random.normal(scale=1./num_features, size=(num_users, num_features))\n",
    "    V = np.random.normal(scale=1./num_features, size=(num_items, num_features))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        interaction_file.seek(0)\n",
    "        for line in interaction_file:\n",
    "            user_id, app_id, interaction = line.strip().split(\",\")\n",
    "            user_id, app_id = int(user_id), int(app_id)\n",
    "            interaction = int(interaction == True)\n",
    "            prediction = np.dot(U[user_id], V[app_id])\n",
    "            error = interaction - prediction\n",
    "            U[user_id] += learning_rate * (error * V[app_id] - reg_param * U[user_id])\n",
    "            V[app_id] += learning_rate * (error * U[user_id] - reg_param * V[app_id])\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} completed.\")\n",
    "    return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_file = open(interaction_file_path, mode='r') \n",
    "train_file = open(train_file_path, mode='r') \n",
    "test_file = open(test_file_path, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 completed.\n",
      "Epoch 2/5 completed.\n",
      "Epoch 3/5 completed.\n",
      "Epoch 4/5 completed.\n",
      "Epoch 5/5 completed.\n"
     ]
    }
   ],
   "source": [
    "num_users = len(user_ids)\n",
    "num_items = len(app_ids)\n",
    "U, V = funk_svd_file(interaction_file, num_users, num_items, num_features=20, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(test_file, U, V):\n",
    "    test_file.seek(0)\n",
    "    total_error = 0\n",
    "    count = 0\n",
    "    for line in test_file:\n",
    "        user_id, app_id, interaction = line.strip().split(\",\")\n",
    "        user_id, app_id = int(user_id), int(app_id)\n",
    "        interaction = int(interaction == True)\n",
    "        prediction = np.dot(U[user_id], V[app_id])\n",
    "        error = (interaction - prediction) ** 2\n",
    "        total_error += error\n",
    "        count += 1\n",
    "    rmse = np.sqrt(total_error / count)\n",
    "    print(f\"RMSE on Test Data: {rmse:.4f}\")\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Test Data: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.0022089374009210574)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_on_test(test_file, U, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_games_from_files(user_id, U, V, top_n=5):\n",
    "    # U = np.loadtxt(u_matrix_file.name, delimiter=\",\")\n",
    "    # V = np.loadtxt(v_matrix_file.name, delimiter=\",\")\n",
    "    # print(V)\n",
    "    user_index = user_idx[user_id]\n",
    "    predictions = np.dot(U[user_index], V.T)\n",
    "    top_games_idx = np.argsort(-predictions)[:top_n]\n",
    "    recommended_game_ids = [app_ids[idx] for idx in top_games_idx]\n",
    "    return games[games['app_id'].isin(recommended_game_ids)][['app_id', 'title', 'rating', 'price_final']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        app_id                          title         rating  price_final\n",
      "11965  1662910                     GridlessDB       Positive        19.99\n",
      "24469  1892680           Vitality Girl Ⅱ:Fire       Positive         3.99\n",
      "30913   761000        Floresia I : Intemporel          Mixed         0.00\n",
      "33569   790450                         ANYKEY  Very Positive         0.00\n",
      "37120   452000  Military Life: Tank Simulator          Mixed         3.99\n"
     ]
    }
   ],
   "source": [
    "user_to_recommend = user_ids[0]\n",
    "recommendations = recommend_games_from_files(user_to_recommend, U, V)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
