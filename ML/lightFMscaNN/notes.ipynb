{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM Game Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 01:04:00.954902: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-25 01:04:00.956424: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-25 01:04:00.982877: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-25 01:04:00.983426: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-25 01:04:01.582934: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# -----------------=[ Load Dependencies ]=----------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scann\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import load_npz\n",
    "import pickle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load preprocessed data\n",
    "We have original data:\n",
    "1. games.csv\n",
    "2. users.csv\n",
    "3. recommendations.csv\n",
    "4. games_metadata.json\n",
    "\n",
    "...\n",
    "\n",
    "Then we preprocessed the original data by getting rid of games with less than 15 reviews, in order to decrease the sparisty and maintain only valuable information.\n",
    "\n",
    "Preprocessed data:\n",
    "1. rating_matrix_sparse.npz\n",
    "2. test_matrix.npz\n",
    "3. train_matrix.npz\n",
    "4. train_and_test.npz\n",
    "\n",
    "\n",
    "Now let's jump into the code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------=[ Data reading ]=----------------\n",
    "\n",
    "users = pd.read_csv('./data/users.csv')\n",
    "games = pd.read_csv('./data/games.csv')\n",
    "recommendations = pd.read_csv('./data/recommendations.csv')\n",
    "gamesMetadata = pd.read_json('./data/games_metadata.json', lines=True)\n",
    "\n",
    "interactions = load_npz('./data/train_and_test.npz').tocsr()\n",
    "\n",
    "# Test users with 40% of history (This is used for testing)\n",
    "rest_test = load_npz('./data/rest_test.npz').tocsr()\n",
    "\n",
    "# Test users with 100% history (Used for getting user indicies)\n",
    "test_matrix = load_npz('./data/test_matrix.npz').tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mappers\n",
    "Then we create mappers:   \n",
    "index -> app_id / user_id  \n",
    "app_id / user_id -> index\n",
    "\n",
    "This is mostly used for creating sparse matrices due to the fact that app_id or user_id can be very high and we want to keep everything in order. So we just use their indexes as cooridinates in sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------=[ Mappers ]=-------------------\n",
    "\n",
    "userIds = users['user_id'].unique()\n",
    "gameIds = games['app_id'].unique()\n",
    "\n",
    "mapUserId = {user_id: idx for idx, user_id in enumerate(userIds)}\n",
    "mapGameId = {game_id: idx for idx, game_id in enumerate(gameIds)}\n",
    "mapUserIndex = {idx: user_id for user_id, idx in mapUserId.items()}\n",
    "mapGameIndex = {idx: game_id for game_id, idx in mapGameId.items()}\n",
    "\n",
    "mapToTitle = lambda game_id: games[games['app_id'] == game_id]['title'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Game features\n",
    "We use game features as additional way to keep similar games closely together. This is widely used in LightFM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------=[ Game Features ]=-------------------\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "feature_matrix = mlb.fit_transform(gamesMetadata['tags'])\n",
    "\n",
    "feature_matrix_df = pd.DataFrame(feature_matrix, columns=mlb.classes_)\n",
    "\n",
    "dataset = Dataset()\n",
    "\n",
    "dataset.fit(\n",
    "  items=gameIds,\n",
    "  users=userIds,\n",
    "  item_features=feature_matrix_df\n",
    ")\n",
    "\n",
    "item_features = dataset.build_item_features(\n",
    "    (row['app_id'], row['tags']) for _, row in gamesMetadata.iterrows()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model training and fine tuning\n",
    "With these functions we train our LightFM model. We also can tweak a bunch of parameters in order to squeeze out better metrics. More about them later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------=[ Model training ]=-------------------\n",
    "def fit(model, name, epochs=100):\n",
    "  for epoch in range(1, epochs + 1):\n",
    "    model.fit_partial(interactions, epochs=1, num_threads=15)\n",
    "\n",
    "    val_recall = recall_at_k(\n",
    "      model,\n",
    "      rest_test,\n",
    "      k=20,\n",
    "      num_threads=15\n",
    "    ).mean()\n",
    "\n",
    "    print(f\"Epoch {epoch}: Value of Recall@20 = {val_recall:.4f}\")\n",
    "\n",
    "    # with open(f'./data/model/lightfm_{name}.pkl', 'wb') as f:\n",
    "    #   pickle.dump(model, f)\n",
    "\n",
    "\n",
    "def loadModel(name) -> LightFM:\n",
    "  with open(f'./data/model/lightfm_{name}.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "space = {\n",
    "    'no_components': hp.choice('no_components', [32, 64, 100, 128]),\n",
    "    'loss': hp.choice('loss', ['warp', 'warp-kos', 'bpr']),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-4), np.log(0.1)),\n",
    "    'k': hp.choice('k', [10, 15, 20]),\n",
    "    'user_alpha': hp.loguniform('user_alpha', np.log(1e-6), np.log(1e-3)),\n",
    "    'item_alpha': hp.loguniform('item_alpha', np.log(1e-6), np.log(1e-3)),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Initialize model with sampled hyperparameters\n",
    "    model = LightFM(\n",
    "        no_components=params['no_components'],\n",
    "        loss=params['loss'],\n",
    "        k=params['k'],\n",
    "        user_alpha=params['user_alpha'],\n",
    "        item_alpha=params['item_alpha'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train for fewer epochs during hyperparameter search (e.g., 30)\n",
    "    for _ in tqdm(range(30)):\n",
    "        model.fit_partial(interactions, num_threads=20)\n",
    "    \n",
    "    # Calculate validation recall\n",
    "    val_recall = recall_at_k(model, rest_test, k=20, num_threads=20).mean()\n",
    "    \n",
    "    # Hyperopt minimizes the loss, so return negative recall\n",
    "    return {\n",
    "        'loss': -val_recall,\n",
    "        'status': STATUS_OK,\n",
    "        'params': params,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "  3%|3         | 1/30 [00:12<06:08, 12.71s/it]\n",
      "  7%|6         | 2/30 [00:21<04:54, 10.51s/it]\n",
      " 10%|#         | 3/30 [00:30<04:21,  9.69s/it]\n",
      " 13%|#3        | 4/30 [00:39<04:03,  9.37s/it]\n",
      " 17%|#6        | 5/30 [00:48<03:52,  9.29s/it]\n",
      " 20%|##        | 6/30 [00:57<03:41,  9.25s/it]\n",
      " 23%|##3       | 7/30 [01:06<03:33,  9.27s/it]\n",
      " 27%|##6       | 8/30 [01:15<03:22,  9.22s/it]\n",
      " 30%|###       | 9/30 [01:25<03:14,  9.24s/it]\n",
      " 33%|###3      | 10/30 [01:34<03:05,  9.30s/it]\n",
      " 37%|###6      | 11/30 [01:44<02:57,  9.33s/it]\n",
      " 40%|####      | 12/30 [01:53<02:47,  9.31s/it]\n",
      " 43%|####3     | 13/30 [02:03<02:40,  9.42s/it]\n",
      " 47%|####6     | 14/30 [02:12<02:31,  9.48s/it]\n",
      " 50%|#####     | 15/30 [02:22<02:23,  9.59s/it]\n",
      " 53%|#####3    | 16/30 [02:32<02:16,  9.77s/it]\n",
      " 57%|#####6    | 17/30 [02:42<02:05,  9.63s/it]\n",
      " 60%|######    | 18/30 [02:51<01:53,  9.45s/it]\n",
      " 63%|######3   | 19/30 [03:00<01:44,  9.51s/it]\n",
      " 67%|######6   | 20/30 [03:10<01:35,  9.54s/it]\n",
      " 70%|#######   | 21/30 [03:19<01:25,  9.51s/it]\n",
      " 73%|#######3  | 22/30 [03:28<01:15,  9.42s/it]\n",
      " 77%|#######6  | 23/30 [03:37<01:04,  9.20s/it]\n",
      " 80%|########  | 24/30 [03:47<00:55,  9.31s/it]\n",
      " 83%|########3 | 25/30 [03:57<00:47,  9.46s/it]\n",
      " 87%|########6 | 26/30 [04:06<00:37,  9.43s/it]\n",
      " 90%|######### | 27/30 [04:16<00:28,  9.50s/it]\n",
      " 93%|#########3| 28/30 [04:25<00:18,  9.44s/it]\n",
      " 97%|#########6| 29/30 [04:34<00:09,  9.43s/it]\n",
      "100%|##########| 30/30 [04:44<00:00,  9.40s/it]\n",
      "100%|##########| 30/30 [04:44<00:00,  9.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [04:44<3:52:15, 284.40s/trial, best loss: -0.13266423240325953]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "  3%|3         | 1/30 [00:11<05:39, 11.72s/it]\n",
      "  7%|6         | 2/30 [00:20<04:36,  9.86s/it]\n",
      " 10%|#         | 3/30 [00:28<04:09,  9.25s/it]\n",
      " 13%|#3        | 4/30 [00:37<03:52,  8.95s/it]\n",
      " 17%|#6        | 5/30 [00:45<03:41,  8.86s/it]\n",
      " 20%|##        | 6/30 [00:54<03:29,  8.75s/it]\n",
      " 23%|##3       | 7/30 [01:03<03:19,  8.68s/it]\n",
      " 27%|##6       | 8/30 [01:11<03:10,  8.67s/it]\n",
      " 30%|###       | 9/30 [01:20<03:01,  8.64s/it]\n",
      " 33%|###3      | 10/30 [01:28<02:52,  8.61s/it]\n",
      " 37%|###6      | 11/30 [01:37<02:43,  8.58s/it]\n",
      " 40%|####      | 12/30 [01:45<02:34,  8.57s/it]\n",
      " 43%|####3     | 13/30 [01:54<02:25,  8.56s/it]\n",
      " 47%|####6     | 14/30 [02:02<02:16,  8.55s/it]\n",
      " 50%|#####     | 15/30 [02:11<02:08,  8.55s/it]\n",
      " 53%|#####3    | 16/30 [02:20<01:59,  8.54s/it]\n",
      " 57%|#####6    | 17/30 [02:28<01:51,  8.55s/it]\n",
      " 60%|######    | 18/30 [02:37<01:42,  8.57s/it]\n",
      " 63%|######3   | 19/30 [02:45<01:34,  8.57s/it]\n",
      " 67%|######6   | 20/30 [02:54<01:25,  8.56s/it]\n",
      " 70%|#######   | 21/30 [03:02<01:16,  8.54s/it]\n",
      " 73%|#######3  | 22/30 [03:11<01:08,  8.56s/it]\n",
      " 77%|#######6  | 23/30 [03:19<00:59,  8.56s/it]\n",
      " 80%|########  | 24/30 [03:28<00:51,  8.56s/it]\n",
      " 83%|########3 | 25/30 [03:37<00:42,  8.55s/it]\n",
      " 87%|########6 | 26/30 [03:45<00:34,  8.57s/it]\n",
      " 90%|######### | 27/30 [03:54<00:25,  8.57s/it]\n",
      " 93%|#########3| 28/30 [04:02<00:17,  8.57s/it]\n",
      " 97%|#########6| 29/30 [04:11<00:08,  8.56s/it]\n",
      "100%|##########| 30/30 [04:19<00:00,  8.56s/it]\n",
      "100%|##########| 30/30 [04:19<00:00,  8.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [09:04<3:36:09, 270.20s/trial, best loss: -0.13266423240325953]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()  # Track results\n",
    "best_params = fmin(\n",
    "    fn=objective,      # Objective function\n",
    "    space=space,       # Search space\n",
    "    algo=tpe.suggest,  # Optimization algorithm (Tree-structured Parzen Estimator)\n",
    "    max_evals=50,      # Number of trials (increase for better results)\n",
    "    trials=trials,     # Store results\n",
    "    verbose=True,      # Show progress\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LightFM(\n",
    "    no_components=best_params['no_components'],\n",
    "    loss=best_params['loss'],\n",
    "    k=best_params['k'],\n",
    "    user_alpha=best_params['user_alpha'],\n",
    "    item_alpha=best_params['item_alpha'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train longer (e.g., 100 epochs)\n",
    "fit(final_model, name='tuned_model', epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Value of Recall@20 = 0.0833\n",
      "Epoch 2: Value of Recall@20 = 0.0920\n",
      "Epoch 3: Value of Recall@20 = 0.0997\n",
      "Epoch 4: Value of Recall@20 = 0.1042\n",
      "Epoch 5: Value of Recall@20 = 0.1074\n",
      "Epoch 6: Value of Recall@20 = 0.1081\n",
      "Epoch 7: Value of Recall@20 = 0.1115\n",
      "Epoch 8: Value of Recall@20 = 0.1149\n",
      "Epoch 9: Value of Recall@20 = 0.1162\n",
      "Epoch 10: Value of Recall@20 = 0.1170\n",
      "Epoch 11: Value of Recall@20 = 0.1182\n",
      "Epoch 12: Value of Recall@20 = 0.1189\n",
      "Epoch 13: Value of Recall@20 = 0.1197\n",
      "Epoch 14: Value of Recall@20 = 0.1203\n",
      "Epoch 15: Value of Recall@20 = 0.1228\n",
      "Epoch 16: Value of Recall@20 = 0.1245\n",
      "Epoch 17: Value of Recall@20 = 0.1257\n",
      "Epoch 18: Value of Recall@20 = 0.1261\n",
      "Epoch 19: Value of Recall@20 = 0.1278\n",
      "Epoch 20: Value of Recall@20 = 0.1284\n",
      "Epoch 21: Value of Recall@20 = 0.1293\n",
      "Epoch 22: Value of Recall@20 = 0.1296\n",
      "Epoch 23: Value of Recall@20 = 0.1292\n",
      "Epoch 24: Value of Recall@20 = 0.1299\n",
      "Epoch 25: Value of Recall@20 = 0.1309\n",
      "Epoch 26: Value of Recall@20 = 0.1317\n",
      "Epoch 27: Value of Recall@20 = 0.1322\n",
      "Epoch 28: Value of Recall@20 = 0.1327\n",
      "Epoch 29: Value of Recall@20 = 0.1329\n",
      "Epoch 30: Value of Recall@20 = 0.1332\n",
      "Epoch 31: Value of Recall@20 = 0.1336\n",
      "Epoch 32: Value of Recall@20 = 0.1348\n",
      "Epoch 33: Value of Recall@20 = 0.1348\n",
      "Epoch 34: Value of Recall@20 = 0.1357\n",
      "Epoch 35: Value of Recall@20 = 0.1357\n",
      "Epoch 36: Value of Recall@20 = 0.1372\n",
      "Epoch 37: Value of Recall@20 = 0.1381\n",
      "Epoch 38: Value of Recall@20 = 0.1380\n",
      "Epoch 39: Value of Recall@20 = 0.1387\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10068/43047922.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_10068/4045539963.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, name, epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     val_recall = recall_at_k(\n",
      "\u001b[0;32m~/Dev/University/GameRecommender/ML/env/lib/python3.8/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36mfit_partial\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             self._run_epoch(\n\u001b[0m\u001b[1;32m    656\u001b[0m                 \u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dev/University/GameRecommender/ML/env/lib/python3.8/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, item_features, user_features, interactions, sample_weight, num_threads, loss)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;31m# Call the estimation routines.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"warp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             fit_warp(\n\u001b[0m\u001b[1;32m    697\u001b[0m                 \u001b[0mCSRMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0mCSRMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LightFM(\n",
    "  no_components=64,\n",
    "  loss='warp',\n",
    "  k=20,\n",
    "  learning_rate=0.01,\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "fit(model, '3', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model prediction / recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel('64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate popularity as interaction counts (train set only)\n",
    "train_popularity = np.array(interactions.sum(axis=0)).flatten()\n",
    "\n",
    "# Apply Laplace smoothing to avoid zero-division errors\n",
    "train_popularity += 1\n",
    "\n",
    "# Normalize to [0,1] using log scaling (handles long-tail distribution)\n",
    "log_popularity = np.log(train_popularity)\n",
    "popularity_weights = (log_popularity - log_popularity.min()) / (log_popularity.max() - log_popularity.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendD(user_id, k, alpha=0.8):\n",
    "  # Get items already interacted with IN TRAINING DATA\n",
    "  _, known_items = interactions[user_id].nonzero()\n",
    "  \n",
    "  # Get all possible candidate items\n",
    "  all_items = np.arange(interactions.shape[1])\n",
    "  candidate_items = np.setdiff1d(all_items, known_items)\n",
    "  \n",
    "  # Score only unseen items\n",
    "  scores = model.predict(\n",
    "      user_ids=np.full(len(candidate_items), user_id),\n",
    "      item_ids=candidate_items,\n",
    "      num_threads=20\n",
    "  )\n",
    "  \n",
    "  # Get popularity scores for candidates\n",
    "  pop_scores = popularity_weights[candidate_items]\n",
    "  \n",
    "  # Blend scores\n",
    "  combined_scores = alpha * scores + (1 - alpha) * pop_scores\n",
    "  \n",
    "  # Get top-k items\n",
    "  top_k_indices = np.argsort(-scores)[:k]\n",
    "  return candidate_items[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 16:50:48.275478: I scann/base/single_machine_factory_scann.cc:153] Single-machine AH training with dataset size = 50872, 20 thread(s).\n"
     ]
    }
   ],
   "source": [
    "# -----------------=[ Prediction ]=------------------\n",
    "\n",
    "def listUserLikedGames(user_id, matrix):\n",
    "  user_index = mapUserId[user_id]\n",
    "  user_ratings = matrix[user_index].toarray()[0]\n",
    "\n",
    "  games = []\n",
    "\n",
    "  for idx, rating in enumerate(user_ratings):\n",
    "    if rating == 1:\n",
    "      games.append(mapGameIndex[idx])\n",
    "\n",
    "  return games\n",
    "\n",
    "\n",
    "def embed_user(user_id):\n",
    "  user_games = listUserLikedGames(user_id, interactions)\n",
    "\n",
    "  if len(user_games) == 0:\n",
    "    return np.zeros(64)\n",
    "  \n",
    "  game_indices = [mapGameId[game_id] for game_id in user_games]\n",
    "  game_embeddings = model.item_embeddings[game_indices]\n",
    "\n",
    "  user_embedding = np.mean(game_embeddings, axis=0)\n",
    "\n",
    "  \n",
    "  return user_embedding\n",
    "\n",
    "searcher = scann.scann_ops_pybind.builder(model.item_embeddings, 20, \"dot_product\").score_ah(6, hash_type=\"lut256\", training_iterations=11).build()\n",
    "def recommend2(user_id, k):\n",
    "    user_embedding = embed_user(user_id)\n",
    "    indices, scores = searcher.search(user_embedding)\n",
    "\n",
    "    sorted_indices = np.argsort(-scores)\n",
    "    sorted_item_indices = [indices[i] for i in sorted_indices]\n",
    "\n",
    "    return sorted_item_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Various metrics testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_k(test_interactions, train_interactions, k=20):\n",
    "  test_users = np.unique(test_interactions.nonzero()[0])\n",
    "  ndcg_scores = []\n",
    "\n",
    "  for user_id in tqdm(test_users):\n",
    "    true_positives = test_interactions[user_id].indices\n",
    "    train_positives = train_interactions[user_id].indices\n",
    "    true_positives = np.setdiff1d(true_positives, train_positives)\n",
    "\n",
    "    recommended_items = recommend(user_id, k)\n",
    "\n",
    "    relevance = np.isin(recommended_items, true_positives).astype(float)\n",
    "    \n",
    "    dcg = 0.0\n",
    "    for pos, rel in enumerate(relevance):\n",
    "      dcg += rel / np.log2(pos + 2)\n",
    "    \n",
    "    ideal_relevance = np.zeros_like(relevance)\n",
    "    ideal_relevance[:min(k, len(true_positives))] = 1.0\n",
    "    idcg = 0.0\n",
    "    for pos, rel in enumerate(ideal_relevance):\n",
    "      idcg += rel / np.log2(pos + 2)\n",
    "    \n",
    "    ndcg = (dcg / idcg) if idcg > 0 else 0.0\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "  return np.mean(ndcg_scores) if ndcg_scores else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitrate_k(test_interactions, train_interactions, k=20):\n",
    "  test_users = np.unique(test_interactions.nonzero()[0])\n",
    "  hits = 0\n",
    "\n",
    "  for user_id in tqdm(test_users):\n",
    "    true_positives = test_interactions[user_id].indices\n",
    "    train_positives = train_interactions[user_id].indices\n",
    "    true_positives = np.setdiff1d(true_positives, train_positives)\n",
    "    \n",
    "    recommended_items = recommend(user_id, k)\n",
    "\n",
    "    if len(np.intersect1d(recommended_items, true_positives)) > 0:\n",
    "      hits += 1\n",
    "\n",
    "  return hits / len(test_users) if len(test_users) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1932/1932 [00:21<00:00, 88.60it/s]\n",
      "100%|██████████| 1932/1932 [00:21<00:00, 87.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RECALL@20: 0.1473103519668737\n",
      "Test HITRATE@20: 0.5419254658385093\n",
      "Test PRECISION@20: 0.05372670807453417\n",
      "Test NDCG@20: 0.10876538702622637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import recmetrics\n",
    "\n",
    "def test_metrics(test_interactions, train_interactions, k):\n",
    "  test_users = np.unique(test_interactions.nonzero()[0])\n",
    "  y_true = []\n",
    "  y_pred = []\n",
    "\n",
    "  for user_id in test_users:\n",
    "    true_positives = test_interactions[user_id].indices\n",
    "    train_positives = train_interactions[user_id].indices\n",
    "    \n",
    "    y_true.append(np.setdiff1d(true_positives, train_positives))\n",
    "    y_pred.append(recommend(user_id, k))\n",
    "\n",
    "  recall = recmetrics.recommender_recall(y_pred, y_true)\n",
    "  hitrate = hitrate_k(test_interactions, train_interactions, k)\n",
    "  precision = recmetrics.recommender_precision(y_pred, y_true)  \n",
    "  ndcg = ndcg_k(test_interactions, train_interactions, k)\n",
    "\n",
    "  return recall, hitrate, precision, ndcg\n",
    "\n",
    "\n",
    "recall, hitrate, precision, ndcg = test_metrics(rest_test, interactions, 20)\n",
    "\n",
    "\n",
    "print(f'Test RECALL@{20}: {recall}')\n",
    "print(f'Test HITRATE@{20}: {hitrate}')\n",
    "print(f'Test PRECISION@{20}: {precision}')\n",
    "print(f'Test NDCG@{20}: {ndcg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel('64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1932/1932 [00:19<00:00, 97.98it/s]\n",
      "100%|██████████| 1932/1932 [00:20<00:00, 94.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1473103519668737, 0.5419254658385093, 0.05372670807453417, 0.10876538702622637)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")  # Replace with your actual path\n",
    "\n",
    "from metrics import *\n",
    "\n",
    "class modelL:\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "  \n",
    "  def recommend(self, user_id, k):\n",
    "    return recommendD(user_id, k, 0.8)\n",
    "\n",
    "print(test_metrics(modelL(model), 20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
