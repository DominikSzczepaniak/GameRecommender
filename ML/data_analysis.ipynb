{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz, save_npz, coo_matrix\n",
    "\n",
    "users = pd.read_csv('./data/users.csv')\n",
    "games = pd.read_csv('./data/games.csv')\n",
    "\n",
    "unique_user_ids = users['user_id'].unique()\n",
    "unique_game_ids = games['app_id'].unique()\n",
    "\n",
    "user_index = {user_id: idx for idx, user_id in enumerate(unique_user_ids)}\n",
    "app_index = {game_id: idx for idx, game_id in enumerate(unique_game_ids)}\n",
    "reverse_user_index = {idx: user_id for user_id, idx in user_index.items()}\n",
    "reverse_app_index = {idx: game_id for game_id, idx in app_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_matrix_sparse = load_npz('rating_matrix_sparse.npz')\n",
    "row_indices = rating_matrix_sparse.row\n",
    "col_indices = rating_matrix_sparse.col\n",
    "data = rating_matrix_sparse.data\n",
    "\n",
    "# Triplets of (row, col, 0/1)\n",
    "entries = np.vstack((row_indices, col_indices, data)).T\n",
    "\n",
    "positive_interactions = data > 0\n",
    "user_row_counts_positive = np.bincount(row_indices, weights=data * positive_interactions, minlength=rating_matrix_sparse.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_15 = np.where(user_row_counts_positive >= 15)[0]\n",
    "users_5_14 = np.where((user_row_counts_positive < 15) & (user_row_counts_positive >= 5))[0]\n",
    "users_diff = np.setdiff1d(row_indices, np.union1d(users_15, users_5_14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_entries_15 = entries[np.isin(entries[:, 0], users_15)]\n",
    "filtered_entries_5_14 = entries[np.isin(entries[:, 0], users_5_14)]\n",
    "filtered_entries_diff = entries[np.isin(entries[:, 0], users_diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_15 = np.unique(filtered_entries_15[:, 0])\n",
    "selected_users_15 = np.random.choice(unique_users_15, size=1000, replace=False)\n",
    "\n",
    "test_entries_15 = filtered_entries_15[np.isin(filtered_entries_15[:, 0], selected_users_15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_5_14 = np.unique(filtered_entries_5_14[:, 0])\n",
    "selected_users_5_14 = np.random.choice(unique_users_5_14, size=500, replace=False)\n",
    "\n",
    "test_entries_5_14 = filtered_entries_5_14[np.isin(filtered_entries_5_14[:, 0], selected_users_5_14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users_diff = np.unique(filtered_entries_diff[:, 0])\n",
    "selected_users_diff = np.random.choice(unique_users_diff, size=500, replace=False)\n",
    "\n",
    "test_entries_diff = filtered_entries_diff[np.isin(filtered_entries_diff[:, 0], selected_users_diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TEST IF IT IS CORRECT \n",
    "unique_users = np.unique(test_entries_15[:, 0])\n",
    "print(len(unique_users))\n",
    "\n",
    "unique_users = np.unique(test_entries_5_14[:, 0])\n",
    "print(len(unique_users))\n",
    "\n",
    "unique_users = np.unique(test_entries_diff[:, 0])\n",
    "print(len(unique_users))\n",
    "\n",
    "# Ladies and Gentleman... Skibidi Toilet right here:\n",
    "# test_entries = filtered_entries[:5000]\n",
    "\n",
    "# REST IS OKAY...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files train_matrix.npz and test_matrix.npz have been created.\n"
     ]
    }
   ],
   "source": [
    "test_entries = np.vstack((test_entries_15, test_entries_5_14, test_entries_diff))\n",
    "\n",
    "# Create a mask for the train set (entries not in the test set)\n",
    "test_indices_set = set(map(tuple, test_entries))\n",
    "train_mask = np.array([tuple(entry) not in test_indices_set for entry in entries])\n",
    "train_entries = entries[train_mask]\n",
    "\n",
    "# Create train and test matrices\n",
    "num_users, num_games = rating_matrix_sparse.shape\n",
    "train_matrix = coo_matrix((train_entries[:, 2], (train_entries[:, 0], train_entries[:, 1])),\n",
    "                          shape=(num_users, num_games))\n",
    "test_matrix = coo_matrix((test_entries[:, 2], (test_entries[:, 0], test_entries[:, 1])),\n",
    "                         shape=(num_users, num_games))\n",
    "\n",
    "# Save the matrices\n",
    "save_npz('train_matrix.npz', train_matrix)\n",
    "save_npz('test_matrix.npz', test_matrix)\n",
    "\n",
    "print(\"Files train_matrix.npz and test_matrix.npz have been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files train_and_test.npz and rest_test.npz have been created.\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import load_npz, save_npz, coo_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Load the train and test matrices\n",
    "train_matrix = load_npz('train_matrix.npz')\n",
    "test_matrix = load_npz('test_matrix.npz')\n",
    "\n",
    "# Convert test matrix to COO format for easy manipulation\n",
    "if not isinstance(test_matrix, coo_matrix):\n",
    "    test_matrix = coo_matrix(test_matrix)\n",
    "\n",
    "# Extract row, column, and data from test matrix\n",
    "test_row = test_matrix.row\n",
    "test_col = test_matrix.col\n",
    "test_data = test_matrix.data\n",
    "\n",
    "# Group test entries by user_id\n",
    "test_entries_by_user = {}\n",
    "for row, col, data in zip(test_row, test_col, test_data):\n",
    "    if row not in test_entries_by_user:\n",
    "        test_entries_by_user[row] = []\n",
    "    test_entries_by_user[row].append((col, data))\n",
    "\n",
    "# Variables to store train_and_test and rest_test data\n",
    "train_and_test_rows = []\n",
    "train_and_test_cols = []\n",
    "train_and_test_data = []\n",
    "\n",
    "rest_test_rows = []\n",
    "rest_test_cols = []\n",
    "rest_test_data = []\n",
    "\n",
    "np.random.seed(42)  # Ensure reproducibility\n",
    "\n",
    "# Split test data for each user into 60% and 40%\n",
    "for user, entries in test_entries_by_user.items():\n",
    "    entries = np.array(entries)  # Convert to numpy array\n",
    "\n",
    "    # Shuffle entries for randomness for each user\n",
    "    np.random.shuffle(entries)\n",
    "    \n",
    "    num_entries = len(entries)\n",
    "\n",
    "    split_idx = int(num_entries * 0.6)  # Calculate 60% split point\n",
    "    \n",
    "    # Split into train_and_test (60%) and rest_test (40%)\n",
    "    for col, data in entries[:split_idx]:\n",
    "        train_and_test_rows.append(user)\n",
    "        train_and_test_cols.append(col)\n",
    "        train_and_test_data.append(data)\n",
    "\n",
    "    for col, data in entries[split_idx:]:\n",
    "        rest_test_rows.append(user)\n",
    "        rest_test_cols.append(col)\n",
    "        rest_test_data.append(data)\n",
    "\n",
    "# Create train_and_test matrix\n",
    "train_and_test_matrix = coo_matrix((\n",
    "    np.hstack([train_matrix.data, train_and_test_data]),\n",
    "    (\n",
    "        np.hstack([train_matrix.row, train_and_test_rows]),\n",
    "        np.hstack([train_matrix.col, train_and_test_cols])\n",
    "    )\n",
    "), shape=train_matrix.shape)\n",
    "\n",
    "# Create rest_test matrix\n",
    "rest_test_matrix = coo_matrix((\n",
    "    rest_test_data,\n",
    "    (rest_test_rows, rest_test_cols)\n",
    "), shape=test_matrix.shape)\n",
    "\n",
    "# Save the new matrices\n",
    "save_npz('train_and_test.npz', train_and_test_matrix)\n",
    "save_npz('rest_test.npz', rest_test_matrix)\n",
    "\n",
    "print(\"Files train_and_test.npz and rest_test.npz have been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "recommendations = pd.read_csv('./recommendations.csv')\n",
    "\n",
    "user_recommendations = recommendations.groupby('user_id')['review_id'].count()\n",
    "app_recommendations = recommendations.groupby('app_id')['review_id'].count()\n",
    "\n",
    "avg_user_recommendations = user_recommendations.mean()\n",
    "avg_app_recommendations = app_recommendations.mean()\n",
    "\n",
    "print(f\"Średnia liczba rekomendacji na użytkownika: {avg_user_recommendations:.2f}\")\n",
    "print(f\"Średnia liczba rekomendacji na grę: {avg_app_recommendations:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(user_recommendations, bins=range(1, 20, 1), color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram liczby rekomendacji na użytkownika')\n",
    "plt.xlabel('Liczba rekomendacji')\n",
    "plt.ylabel('Liczba użytkowników')\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(app_recommendations, bins=range(100, 20000, 100), color='lightgreen', edgecolor='black')\n",
    "plt.title('Histogram liczby rekomendacji na grę')\n",
    "plt.xlabel('Liczba rekomendacji')\n",
    "plt.ylabel('Liczba gier')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Wczytaj dane z pliku recommendations.csv\n",
    "df = pd.read_csv('cleora/recommendations.csv')\n",
    "\n",
    "# 2. Stwórz słownik, gdzie kluczem jest app_id, a wartością liczba wierszy dla tego app_id\n",
    "app_recommendations_count = df['app_id'].value_counts().to_dict()\n",
    "\n",
    "\n",
    "# 3. Stwórz nowy DataFrame, pomijając app_id, które mają mniej niż 15 wystąpień\n",
    "filtered_df = df[df['app_id'].apply(lambda x: app_recommendations_count[x] >= 15)]\n",
    "\n",
    "# 4. Zapisz nowy DataFrame do pliku\n",
    "filtered_df.to_csv('filtered_recommendations.csv', index=False)\n",
    "\n",
    "print(f\"Zapisano przefiltrowany plik z {len(filtered_df)} wierszami.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
